{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet and M2NIST\n",
    "===============\n",
    "\n",
    "[Multidigit MNIST(M2NIST)](https://www.kaggle.com/datasets/farhanhubble/multimnistm2nist)\n",
    "\n",
    "#### Context\n",
    "\n",
    "I created this dataset to teach the basics of fully convolution networks for semantic segmentation of images. Most real-world semantic image segmentation tasks require building huge networks that are slow to train and experiment with. The dataset was generated by selecting up to 3 random 28px x 28px grayscale images from the MNIST dataset and copying them in to a single 64px(height) x 84px(width) image. The digits were pasted so that they did not overlap and no transformations were applied to the original images, so digits in M2NIST maintain the same orientation as the have in MNIST.\n",
    "Content\n",
    "\n",
    "#### Content\n",
    "\n",
    "The dataset has 5000 multi-digit images in combined.npy and 11 segmentation masks for every image in segmented.npy. The files can be read in using `numpy.load()`, for example, as `combined=np.load('combined.npy')` and `segmented = np.load('segmented.npy')`. The data in `combined.npy` has shape `(5000, 64, 84)` while the data in `segmented.npy` has shape `(5000, 64, 84, 11)`. Every element in combined.npy is a grayscale image with up to 3 digits. The corresponding element in segmented.npy is a tensor with 64 rows, 84 columns and 11 layers or channels. Each layer or channel is a binary mask. The k-th layer (0<=k<9) has 1s wherever the digit k is present in the combined image and 0s everywhere else. The last layer `k=10` represents background and has 1s wherever there is no digit in the combined image and 0's wherever at pixels where some digit is present in the original image.\n",
    "Acknowledgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d, Dropout2d, MaxPool2d, ReLU, UpsamplingNearest2d\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision import ops\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image. \n",
    "        # Each block in the encoder consists of two convolutional layers followed by a max-pooling layer, with the exception of the last baseline block which does not include a max-pooling layer.\n",
    "        # -------\n",
    "        # input: 572x572x3\n",
    "        self.e11 = nn.Conv2d(1, 32, kernel_size=3, padding=1) # output: 570x570x64\n",
    "        self.e12 = nn.Conv2d(32, 32, kernel_size=3, padding=1) # output: 568x568x64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 284x284x64\n",
    "\n",
    "        # input: 284x284x64\n",
    "        self.e21 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # output: 282x282x128\n",
    "        self.e22 = nn.Conv2d(64, 64, kernel_size=3, padding=1) # output: 280x280x128\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n",
    "\n",
    "        # input: 140x140x128\n",
    "        self.e31 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 138x138x256\n",
    "        self.e32 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 136x136x256\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n",
    "\n",
    "        # input: 68x68x256\n",
    "        self.e41 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 66x66x512\n",
    "        self.e42 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 64x64x512\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n",
    "\n",
    "\n",
    "        # Baseline\n",
    "        # input: 32x32x512\n",
    "        self.e51 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 30x30x1024\n",
    "        self.e52 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 28x28x1024\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "        \n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "unet_model_str = UNet(10).to(device)\n",
    "summary(unet_model_str, input_size=(1, 64, 64))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetMini(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNetMini, self).__init__()\n",
    "\n",
    "        # Use padding 1 to mimic `padding='same'` in keras,\n",
    "        # use this visualization tool https://ezyang.github.io/convolution-visualizer/index.html\n",
    "        self.block1 = Sequential(\n",
    "            Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.pool1 = MaxPool2d((2, 2))\n",
    "\n",
    "        self.block2 = Sequential(\n",
    "            Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.pool2 = MaxPool2d((2, 2))\n",
    "\n",
    "        self.block3 = Sequential(\n",
    "            Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = UpsamplingNearest2d(scale_factor=2)\n",
    "        self.block4 = Sequential(\n",
    "            Conv2d(192, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        self.up2 = UpsamplingNearest2d(scale_factor=2)\n",
    "        self.block5 = Sequential(\n",
    "            Conv2d(96, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2d = Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.block1(x)\n",
    "        out_pool1 = self.pool1(out1)\n",
    "\n",
    "        out2 = self.block2(out_pool1)\n",
    "        out_pool2 = self.pool1(out2)\n",
    "\n",
    "        out3 = self.block3(out_pool2)\n",
    "\n",
    "        out_up1 = self.up1(out3)\n",
    "        # return out_up1\n",
    "        out4 = torch.cat((out_up1, out2), dim=1)\n",
    "        out4 = self.block4(out4)\n",
    "\n",
    "        out_up2 = self.up2(out4)\n",
    "        out5 = torch.cat((out_up2, out1), dim=1)\n",
    "        out5 = self.block5(out5)\n",
    "\n",
    "        out = self.conv2d(out5)\n",
    "\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "unetmini_model_str = UNetMini(10).to(device)\n",
    "summary(unetmini_model_str, input_size=(1, 64, 84))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2NIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.load('data/M2NIST/combined.npy')\n",
    "segmented = np.load('data/M2NIST/segmented.npy')[:,:,:,:10]\n",
    "\n",
    "print(combined.shape)\n",
    "print(segmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2NISTData(Dataset):\n",
    "    def __init__(self, combined, segmented, samp_size=100, samp_type='trn', transform=None):\n",
    "        self.transform = transform\n",
    "        if samp_type == 'trn':    \n",
    "            self.combined = combined[:samp_size]\n",
    "            self.segmented = segmented[:samp_size]\n",
    "        elif samp_type == 'val':\n",
    "            self.combined = combined[-samp_size:]\n",
    "            self.segmented = segmented[-samp_size:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.combined))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.combined[idx,:,:64].astype(np.uint8)  # np.stack((image, np.zeros_like(image), np.zeros_like(image)), axis=-1)  # pseudo RGB\n",
    "        label = np.moveaxis(self.segmented[idx,:,:64,:], -1, 0).astype(np.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def get_dataloaders(combined_data, segmented_data, train_samp_size=500, val_samp_size=50, batch_size=10):\n",
    "    trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.], std=[1.])])\n",
    "    \n",
    "    train_dataset = M2NISTData(combined=combined_data, segmented=segmented_data,\n",
    "                               samp_size=train_samp_size, samp_type='trn', transform=trans)\n",
    "    val_dataset = M2NISTData(combined=combined_data, segmented=segmented_data,\n",
    "                             samp_size=val_samp_size, samp_type='val', transform=trans)\n",
    "\n",
    "    trn_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return trn_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0], std=[1])])\n",
    "\n",
    "demo_dataset = M2NISTData(combined=combined, segmented=segmented,\n",
    "                          samp_size=20, samp_type='val', transform=demo_trans)\n",
    "\n",
    "img, lab = demo_dataset.__getitem__(2)\n",
    "\n",
    "print(type(img))\n",
    "print(type(lab))\n",
    "print(img.shape, lab.shape)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(2,2,(1,3))\n",
    "plt.imshow(img[0])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(img.ravel(), bins=256)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(lab[2,...])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(height, width, zoom, count):\n",
    "    x, y = zip(*[generate_img_and_mask(height, width, zoom) for i in range(0, count)])\n",
    "\n",
    "    X = np.array(x) * 255\n",
    "    X = X[:,0,:,:].astype(np.uint8)\n",
    "    Y = np.array(y)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def generate_img_and_mask(height, width, zoom):\n",
    "    shape = (height, width)\n",
    "\n",
    "    # triangle_location = get_random_location(*shape)\n",
    "    # circle_location1 = get_random_location(*shape, zoom=zoom)\n",
    "    circle_location2 = get_random_location(*shape, zoom=zoom)\n",
    "    # mesh_location = get_random_location(*shape)\n",
    "    # square_location = get_random_location(*shape, zoom=0.8)\n",
    "    plus_location = get_random_location(*shape, zoom=zoom)\n",
    "\n",
    "    # Create input image\n",
    "    arr = np.zeros(shape, dtype=bool)\n",
    "    # arr = add_triangle(arr, *triangle_location)\n",
    "    # arr = add_circle(arr, *circle_location1)\n",
    "    arr = add_circle(arr, *circle_location2, fill=True)\n",
    "    # arr = add_mesh_square(arr, *mesh_location)\n",
    "    # arr = add_filled_square(arr, *square_location)\n",
    "    arr = add_plus(arr, *plus_location)\n",
    "    arr = np.reshape(arr, (1, height, width)).astype(np.float32)\n",
    "\n",
    "    # Create target masks\n",
    "    masks = np.asarray([\n",
    "        # add_filled_square(np.zeros(shape, dtype=bool), *square_location),\n",
    "        add_circle(np.zeros(shape, dtype=bool), *circle_location2, fill=True),\n",
    "        # add_triangle(np.zeros(shape, dtype=bool), *triangle_location),\n",
    "        # add_circle(np.zeros(shape, dtype=bool), *circle_location1),\n",
    "        #  add_filled_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
    "        # add_mesh_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
    "        add_plus(np.zeros(shape, dtype=bool), *plus_location)\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    return arr, masks\n",
    "\n",
    "\n",
    "def add_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "    arr[x-s,y-s:y+s] = True\n",
    "    arr[x+s,y-s:y+s] = True\n",
    "    arr[x-s:x+s,y-s] = True\n",
    "    arr[x-s:x+s,y+s] = True\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def add_filled_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "\n",
    "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, yy > y - s, yy < y + s]))\n",
    "\n",
    "\n",
    "def logical_and(arrays):\n",
    "    new_array = np.ones(arrays[0].shape, dtype=bool)\n",
    "    for a in arrays:\n",
    "        new_array = np.logical_and(new_array, a)\n",
    "\n",
    "    return new_array\n",
    "\n",
    "\n",
    "def add_mesh_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "\n",
    "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, xx % 2 == 1, yy > y - s, yy < y + s, yy % 2 == 1]))\n",
    "\n",
    "\n",
    "def add_triangle(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    triangle = np.tril(np.ones((size, size), dtype=bool))\n",
    "\n",
    "    arr[x-s:x-s+triangle.shape[0],y-s:y-s+triangle.shape[1]] = triangle\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def add_circle(arr, x, y, size, fill=False):\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "    circle = np.sqrt((xx - x) ** 2 + (yy - y) ** 2)\n",
    "    new_arr = np.logical_or(arr, np.logical_and(circle < size, circle >= size * 0.7 if not fill else True))\n",
    "\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def add_plus(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "    arr[x-1:x+1,y-s:y+s] = True\n",
    "    arr[x-s:x+s,y-1:y+1] = True\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_random_location(width, height, zoom=1.0):\n",
    "    x = int(width * random.uniform(0.1, 0.9))\n",
    "    y = int(height * random.uniform(0.1, 0.9))\n",
    "\n",
    "    size = int(min(width, height) * random.uniform(0.1, 0.2) * zoom)\n",
    "\n",
    "    return (x, y, size)\n",
    "\n",
    "\n",
    "def plot_img_array(img_array, ncol=3):\n",
    "    nrow = len(img_array) // ncol\n",
    "\n",
    "    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4))\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        plots[i // ncol, i % ncol]\n",
    "        plots[i // ncol, i % ncol].imshow(img_array[i])\n",
    "\n",
    "\n",
    "def plot_side_by_side(img_arrays):\n",
    "    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n",
    "\n",
    "    plot_img_array(np.array(flatten_list), ncol=len(img_arrays))\n",
    "\n",
    "\n",
    "def plot_errors(results_dict, title):\n",
    "    markers = itertools.cycle(('+', 'x', 'o'))\n",
    "\n",
    "    plt.title('{}'.format(title))\n",
    "\n",
    "    for label, result in sorted(results_dict.items()):\n",
    "        plt.plot(result, marker=next(markers), label=label)\n",
    "        plt.ylabel('dice_coef')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(loc=3, bbox_to_anchor=(1, 0))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def masks_to_colorimg(masks):\n",
    "    colors = np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n",
    "\n",
    "    colorimg = np.ones((masks.shape[1], masks.shape[2], 3), dtype=np.float32) * 255\n",
    "    channels, height, width = masks.shape\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            selected_colors = colors[masks[:,y,x] > 0.5]\n",
    "\n",
    "            if len(selected_colors) > 0:\n",
    "                colorimg[y,x,:] = np.mean(selected_colors, axis=0)\n",
    "\n",
    "    return colorimg.astype(np.uint8)\n",
    "\n",
    "\n",
    "def generate_images_and_masks_then_plot():\n",
    "    # Generate some random images\n",
    "    input_images, target_masks = generate_random_data(192, 192, count=3)\n",
    "\n",
    "    for x in [input_images, target_masks]:\n",
    "        print(x.shape)\n",
    "        print(x.min(), x.max())\n",
    "\n",
    "    # Change channel-order and make 3 channels for matplot\n",
    "    input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "    # Map each channel (i.e. class) to each color\n",
    "    target_masks_rgb = [masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "    # Left: Input image (black and white), Right: Target mask (6ch)\n",
    "    plot_side_by_side([input_images_rgb, target_masks_rgb])\n",
    "\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesData(Dataset):\n",
    "    def __init__(self, samp_size=100, transform=None):\n",
    "        shapes_combined, shapes_masked = generate_random_data(128, 128, zoom=0.75, count=samp_size)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.combined = shapes_combined\n",
    "        self.segmented = shapes_masked\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.combined))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.combined[idx]\n",
    "        label = torch.tensor(self.segmented[idx], dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image).type(torch.float32)\n",
    "        else:\n",
    "            image = torch.unsqueeze(image, 0).type(torch.float32)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "\n",
    "def get_synth_dataloaders(train_samp_size=500, val_samp_size=50, batch_size=10):\n",
    "    trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.], std=[1.])])\n",
    "    \n",
    "    train_dataset = ShapesData(samp_size=train_samp_size, transform=trans)\n",
    "    val_dataset = ShapesData(samp_size=val_samp_size, transform=trans)\n",
    "\n",
    "    trn_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return trn_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_demo_trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0], std=[1])])\n",
    "shapes_demo_dataset = ShapesData(samp_size=20)\n",
    "\n",
    "shape_img, shape_lab = shapes_demo_dataset.__getitem__(2)\n",
    "\n",
    "print(type(shape_img))\n",
    "print(type(shape_lab))\n",
    "\n",
    "print(shape_img.shape, shape_lab.shape)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax[0].imshow(shape_img[0].numpy())\n",
    "ax[1].imshow(shape_lab[0])\n",
    "ax[2].imshow(shape_lab[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train_loader, val_loader = get_synth_dataloaders(train_samp_size=50, val_samp_size=10, batch_size=5)\n",
    "# model = UNet(2)\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(combined, segmented, train_samp_size=50, val_samp_size=20, batch_size=50)\n",
    "model = UNetMini(10)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.005)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=20)\n",
    "\n",
    "\n",
    "def overlap_metrics(pred, target, eps=1e-5):\n",
    "    pred = F.sigmoid(pred)\n",
    "    pred = (pred > 0.5).float()\n",
    "    \n",
    "    tp = (pred * target).sum(dim=(0, 2, 3))              # TP\n",
    "    fp = (pred * (1 - target)).sum(dim=(0, 2, 3))         # FP\n",
    "    fn = ((1 - pred) * target).sum(dim=(0, 2, 3))        # FN\n",
    "    tn = ((1 - pred) * (1 - target)).sum(dim=(0, 2, 3))  # TN\n",
    "\n",
    "    dice = (2*tp + eps) / (2*tp + fp + fn + eps)\n",
    "    iou = (tp + eps) / (tp + fp + fn + eps)\n",
    "    prec = (tp + eps) / (tp + fp + eps)\n",
    "    # recall = (tp + eps) / (tp + fn + eps)\n",
    "    # specificity = (tn + eps) / (tn + fp + eps)\n",
    "    # pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
    "\n",
    "    return [dice.mean(), iou.mean(), prec.mean()]\n",
    "\n",
    "\n",
    "def calc_loss(pred, target, bce_weight=0.5):\n",
    "    def dice_loss(pred, target, smooth=1e-6):\n",
    "        pred = F.sigmoid(pred)\n",
    "        pred = (pred > 0.5).float()\n",
    "\n",
    "        # pred = torch.softmax(pred, dim=1)\n",
    "        # target_one_hot = nn.functional.one_hot(target, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        intersection = (pred * target).sum(dim=(0,2,3))\n",
    "        union = pred.sum(dim=(0,2, 3)) + target.sum(dim=(0,2, 3))\n",
    "        loss = 1. - 2.*((intersection + smooth) / (union + smooth))\n",
    "\n",
    "        return loss.mean()\n",
    "    \n",
    "    def tversky_loss(pred, target, alpha=0.3, beta=0.7, smooth=1e-6):\n",
    "        pred = F.sigmoid(pred)\n",
    "        pred = (pred > 0.5).float()\n",
    "        \n",
    "        tp = (pred * target).sum(dim=(0, 2, 3))\n",
    "        fp = (pred * (1 - target)).sum(dim=(0,2, 3))\n",
    "        fn = ((1 - pred) * target).sum(dim=(0, 2, 3))\n",
    "\n",
    "        tversky_loss = 1. - ((tp + smooth) / (tp + alpha*fp + beta*fn + smooth))\n",
    "\n",
    "        return tversky_loss.mean()\n",
    "\n",
    "    def iou_loss(pred, target, smooth=1.):\n",
    "        pred = F.sigmoid(pred)\n",
    "        pred = (pred > 0.5).float()\n",
    "\n",
    "        intersection = (pred * target).sum(dim=(2,3))\n",
    "        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n",
    "        iou_loss = (1. - (intersection + smooth) / (union + smooth))\n",
    "        return iou_loss.mean()\n",
    "    \n",
    "\n",
    "    # entropy_loss = F.binary_cross_entropy_with_logits(pred, target)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    entropy_loss = criterion(pred, target)\n",
    "    overlap_loss = dice_loss(pred, target)\n",
    "\n",
    "    loss = (entropy_loss * bce_weight) + (overlap_loss * (1 - bce_weight))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        train_batch_loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        train_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += train_batch_loss.item()*X.size(0)\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss \n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        val_batch_loss = loss_fn(pred, y)\n",
    "        val_loss += val_batch_loss.item()*X.size(0)\n",
    "\n",
    "    val_loss /= len(dataloader)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def print_training_progress_bar(iteration, total,loss_val, length=30):\n",
    "    percent = f\"{100 * (float(iteration+1) / float(total)):.1f}\"\n",
    "    filled_length = int(length * (iteration+1) // (total))\n",
    "    bar = 'â–ˆ' * filled_length + '-' * (length - filled_length)\n",
    "    print(f'\\rEpoch {iteration+1}/{total}| LR:{loss_val[-1]} | Train loss:{loss_val[0]:.4f} | Val loss:{loss_val[1]:.4f}: |{bar}| {percent}%', end = '\\r')\n",
    "    if iteration == total: \n",
    "        print()\n",
    "\n",
    "\n",
    "\n",
    "def update_plot(trin_list, val_list):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(nrows=3, figsize=(10,9))\n",
    "\n",
    "    ax[0].plot(trin_list[0], label='Training loss', marker='o', color='k')\n",
    "    ax[0].plot(val_list[0], label='Val loss', marker='o', color='r')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Loss Over Time', loc='left', fontweight=\"bold\")\n",
    "    ax[0].set_ylim(-0.05, 1.05)\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(trin_list[1]['Prec'], label='Prec.', marker='o', color='m')\n",
    "    ax[1].plot(trin_list[1]['Dice'], label='Dice', marker='o', color='g')\n",
    "    ax[1].plot(trin_list[1]['IoU'], label='IoU', marker='o', color='b')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Value')\n",
    "    ax[1].set_title('Training Metrics Over Time', loc='left', fontweight=\"bold\")\n",
    "    ax[1].set_ylim(-0.05, 1.05)\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].plot(val_list[1]['Prec'], label='Prec.', marker='o', color='m')\n",
    "    ax[2].plot(val_list[1]['Dice'], label='Dice', marker='o', color='g')\n",
    "    ax[2].plot(val_list[1]['IoU'], label='IoU', marker='o', color='b')\n",
    "    ax[2].set_xlabel('Epoch')\n",
    "    ax[2].set_ylabel('Value')\n",
    "    ax[2].set_title('Validation Metrics Over Time', loc='left', fontweight=\"bold\")\n",
    "    ax[2].set_ylim(-0.05, 1.05)\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "train_metrics = {'IoU':[],\n",
    "                 'Dice':[],\n",
    "                 'Prec':[]}\n",
    "val_metrics = {'IoU':[],\n",
    "               'Dice':[],\n",
    "               'Prec':[]}\n",
    "\n",
    "n_epoch = 400\n",
    "for e in range(n_epoch):\n",
    "\n",
    "    # train_loss = train_loop(train_loader, model, calc_loss, optimizer)\n",
    "    # train_loss_list.append(train_loss)\n",
    "\n",
    "    # val_loss = validation_loop(val_loader, model, calc_loss)\n",
    "    # val_loss_list.append(val_loss)\n",
    "\n",
    "\n",
    "    # train loop\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "\n",
    "\n",
    "    for train_input, train_target in train_loader:\n",
    "        train_input, train_target = train_input.to(device), train_target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(train_input)\n",
    "        train_pred = train_pred.to(device)\n",
    "        train_batch_loss = calc_loss(train_pred, train_target)\n",
    "        train_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        train_loss += train_batch_loss.item()\n",
    "\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_om = overlap_metrics(pred=train_pred, target=train_target)\n",
    "    train_metrics['Dice'].append(train_om[0].detach().numpy() / len(train_loader))\n",
    "    train_metrics['IoU'].append(train_om[1].detach().numpy() / len(train_loader))\n",
    "    train_metrics['Prec'].append(train_om[2].detach().numpy() / len(train_loader))\n",
    "\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "\n",
    "    for val_input, val_target in val_loader:\n",
    "        val_input, val_target = val_input.to(device), val_target.to(device)\n",
    "\n",
    "        val_pred = model(val_input)\n",
    "        val_batch_loss = calc_loss(pred=val_pred, target=val_target)\n",
    "        val_loss += val_batch_loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_om = overlap_metrics(pred=val_pred, target=val_target)\n",
    "    val_metrics['Dice'].append(val_om[0].detach().numpy() / len(val_loader))\n",
    "    val_metrics['IoU'].append(val_om[1].detach().numpy() / len(val_loader))\n",
    "    val_metrics['Prec'].append(val_om[2].detach().numpy() / len(val_loader))\n",
    "\n",
    "    update_plot([train_loss_list, train_metrics], [val_loss_list, val_metrics])\n",
    "    print_training_progress_bar(iteration=e, total=n_epoch, loss_val=[train_loss, val_loss, optimizer.param_groups[0]['lr']])\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), '708_mnist_unet)overnight.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(pred, target, metrics, bce_weight=0.5, loss_type='dice'):\n",
    "    # https://stats.stackexchange.com/questions/273537/f1-dice-score-vs-iou\n",
    "    def dice_loss(pred, target, smooth=1.):\n",
    "        pred = pred.contiguous()\n",
    "        target = target.contiguous()\n",
    "\n",
    "        intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "        dice_loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "        \n",
    "        return dice_loss.mean()\n",
    "\n",
    "    def iou_loss(pred, traget, smooth=1.):\n",
    "        intersection = (target * pred).sum(dim=2).sum(dim=2)\n",
    "        iou_loss = (1. - (intersection + smooth) / (target.sum(dim=2).sum(dim=2) + pred.sum(dim=2).sum(dim=2) - intersection + smooth))\n",
    "\n",
    "        return iou_loss.mean()\n",
    "\n",
    "    def overlap_metrics(pred, target, eps=1e-5):\n",
    "        pred = pred.contiguous()\n",
    "        target = target.contiguous()\n",
    "\n",
    "        # metrics\n",
    "        tp = torch.sum(pred * target)  # TP\n",
    "        fp = torch.sum(pred * (1 - target))  # FP\n",
    "        fn = torch.sum((1 - pred) * target)  # FN\n",
    "        tn = torch.sum((1 - pred) * (1 - target))  # TN\n",
    "\n",
    "        pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
    "        dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
    "        precision = (tp + eps) / (tp + fp + eps)\n",
    "        recall = (tp + eps) / (tp + fn + eps)\n",
    "        specificity = (tn + eps) / (tn + fp + eps)\n",
    "        iou = (tp + eps) / (tp + fp + fp + eps)\n",
    "\n",
    "        return [pixel_acc, dice, precision, recall, specificity, iou]\n",
    "    \n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "\n",
    "    if loss_type == 'dice':\n",
    "        overlap_loss = dice_loss(pred, target)\n",
    "    elif loss_type == 'iou':\n",
    "        overlap_loss = iou_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + overlap_loss * (1 - bce_weight)\n",
    "\n",
    "    o_m = overlap_metrics(pred, target)\n",
    "\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['overlap_loss'] += overlap_loss.data.cpu().numpy() * target.size(0)\n",
    "    metrics['Dice'] += o_m[1].data.cpu().numpy() * target.size(0)\n",
    "    metrics['IOU'] += o_m[5].data.cpu().numpy() * target.size(0)\n",
    "    metrics['prec'] += o_m[2].data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss, metrics\n",
    "\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "    print(\"{}: {}\".format(phase, \" | \".join(outputs)))\n",
    "\n",
    "\n",
    "def train_model_externally(model, dat_load, optimizer, scheduler, num_epochs=50):\n",
    "    dataloaders = dat_load\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    train_px_acc_list = []\n",
    "    val_px_acc_list = []\n",
    "\n",
    "    train_prec_list = []\n",
    "    val_prec_list = []\n",
    "\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('=' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['trn', 'val']:\n",
    "            if phase == 'trn':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'trn'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss, metrics = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'trn':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            if phase == 'trn':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "            \n",
    "            if phase == 'trn':\n",
    "                train_loss_list.append(metrics['loss'] / epoch_samples)\n",
    "                train_px_acc_list.append(metrics['IOU'] / epoch_samples)\n",
    "                train_prec_list.append(metrics['prec'] / epoch_samples)\n",
    "            else:\n",
    "                val_loss_list.append(metrics['loss'] / epoch_samples)\n",
    "                val_px_acc_list.append(metrics['IOU'] / epoch_samples)\n",
    "                val_prec_list.append(metrics['prec'] / epoch_samples)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    " \n",
    "    total_time_elapsed = time.time() - train_start_time \n",
    "    print('Best val loss: {:4f}, total train time {:.0f}m {:.0f}s'.format(best_loss, total_time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, [train_loss_list, val_loss_list, train_px_acc_list, val_px_acc_list, train_prec_list, val_prec_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainRun():\n",
    "    def __init__(self, unet_model, dataloaders_dict,\n",
    "                 n_epoch=5, n_class=10, n_test=2, loss_type='dice', loss_bce_weight=0.5, init_lr=1e-3):\n",
    "        self.n_class = n_class\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_test = n_test\n",
    "\n",
    "        self.loss_type = loss_type\n",
    "        self.loss_bce_weight = loss_bce_weight\n",
    "        self.init_lr = init_lr\n",
    "\n",
    "        self.dataloaders_dict = dataloaders_dict\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = unet_model(self.n_class).to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=self.init_lr)\n",
    "        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_loss(pred, target, metrics, bce_weight=0.5, loss_type='dice'):\n",
    "        # https://stats.stackexchange.com/questions/273537/f1-dice-score-vs-iou\n",
    "        def dice_loss(pred, target, smooth=1.):\n",
    "            pred = pred.contiguous()\n",
    "            target = target.contiguous()\n",
    "\n",
    "            intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "            dice_loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "            \n",
    "            return dice_loss.mean()\n",
    "\n",
    "        def iou_loss(pred, traget, smooth=1.):\n",
    "            intersection = (target * pred).sum(dim=2).sum(dim=2)\n",
    "            iou_loss = (1. - (intersection + smooth) / (target.sum(dim=2).sum(dim=2) + pred.sum(dim=2).sum(dim=2) - intersection + smooth))\n",
    "\n",
    "            return iou_loss.mean()\n",
    "\n",
    "        def overlap_metrics(pred, target, eps=1e-5):\n",
    "            pred = pred.contiguous()\n",
    "            target = target.contiguous()\n",
    "\n",
    "            # metrics\n",
    "            tp = torch.sum(pred * target)  # TP\n",
    "            fp = torch.sum(pred * (1 - target))  # FP\n",
    "            fn = torch.sum((1 - pred) * target)  # FN\n",
    "            tn = torch.sum((1 - pred) * (1 - target))  # TN\n",
    "\n",
    "            pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
    "            dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
    "            precision = (tp + eps) / (tp + fp + eps)\n",
    "            recall = (tp + eps) / (tp + fn + eps)\n",
    "            specificity = (tn + eps) / (tn + fp + eps)\n",
    "            iou = (tp + eps) / (tp + fp + fp + eps)\n",
    "\n",
    "            return [pixel_acc, dice, precision, recall, specificity, iou]\n",
    "        \n",
    "        bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "        pred = F.sigmoid(pred)\n",
    "\n",
    "        if loss_type == 'dice':\n",
    "            overlap_loss = dice_loss(pred, target)\n",
    "        elif loss_type == 'iou':\n",
    "            overlap_loss = iou_loss(pred, target)\n",
    "\n",
    "        loss = bce * bce_weight + overlap_loss * (1 - bce_weight)\n",
    "\n",
    "        o_m = overlap_metrics(pred, target)\n",
    "\n",
    "        metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "        metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "        metrics['overlap_loss'] += overlap_loss.data.cpu().numpy() * target.size(0)\n",
    "        metrics['Dice'] += o_m[1].data.cpu().numpy() * target.size(0)\n",
    "        metrics['IOU'] += o_m[5].data.cpu().numpy() * target.size(0)\n",
    "        metrics['prec'] += o_m[2].data.cpu().numpy() * target.size(0)\n",
    "        # metrics['px_acc'] += o_m[0].data.cpu().numpy() * target.size(0)\n",
    "        # metrics['recall'] += o_m[3].data.cpu().numpy() * target.size(0)\n",
    "        # metrics['spec'] += o_m[4].data.cpu().numpy() * target.size(0)\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def print_metrics(metrics, epoch_samples, phase):\n",
    "        outputs = []\n",
    "        for k in metrics.keys():\n",
    "            outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        print(\"{}: {}\".format(phase, \" | \".join(outputs)))\n",
    "\n",
    "    \n",
    "    def train_model(self):\n",
    "        self.best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        self.best_loss = 1e10\n",
    "\n",
    "        self.train_loss_list = []\n",
    "        self.val_loss_list = []\n",
    "\n",
    "        self.train_px_acc_list = []\n",
    "        self.val_px_acc_list = []\n",
    "\n",
    "        self.train_prec_list = []\n",
    "        self.val_prec_list = []\n",
    "\n",
    "        train_start_time = time.time()\n",
    "\n",
    "        for epoch in range(self.n_epoch):\n",
    "            print('== Epoch {}/{} =='.format(epoch, self.n_epoch - 1))\n",
    "            print('-' * 15)\n",
    "\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['trn', 'val']:\n",
    "                if phase == 'trn':\n",
    "                    self.model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    self.model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                metrics = defaultdict(float)\n",
    "                epoch_samples = 0\n",
    "\n",
    "                for inputs, labels in self.dataloaders_dict[phase]:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'trn'):\n",
    "                        outputs = self.model(inputs)\n",
    "                        outputs = F.sigmoid(outputs)\n",
    "                        loss, metrics = self.calc_loss(outputs, labels, metrics,\n",
    "                                                       loss_type=self.loss_type,\n",
    "                                                       bce_weight=self.loss_bce_weight)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'trn':\n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    epoch_samples += inputs.size(0)\n",
    "\n",
    "                if phase == 'trn':\n",
    "                    self.scheduler.step()\n",
    "                    for param_group in self.optimizer.param_groups:\n",
    "                        print(\"LR\", param_group['lr'])\n",
    "                \n",
    "                if phase == 'trn':\n",
    "                    self.train_loss_list.append(metrics['loss'] / epoch_samples)\n",
    "                    self.train_px_acc_list.append(metrics['IOU'] / epoch_samples)\n",
    "                    self.train_prec_list.append(metrics['prec'] / epoch_samples)\n",
    "                else:\n",
    "                    self.val_loss_list.append(metrics['loss'] / epoch_samples)\n",
    "                    self.val_px_acc_list.append(metrics['IOU'] / epoch_samples)\n",
    "                    self.val_prec_list.append(metrics['prec'] / epoch_samples)\n",
    "\n",
    "                self.print_metrics(metrics, epoch_samples, phase)\n",
    "                epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_loss < self.best_loss:\n",
    "                    print(\"saving best model\")\n",
    "                    best_loss = epoch_loss\n",
    "                    self.best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "            time_elapsed = time.time() - epoch_start_time\n",
    "            print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "        total_time_elapsed = time.time() - train_start_time \n",
    "        print('Best val loss: {:4f}, total train time {:.0f}m {:.0f}s'.format(best_loss, total_time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "        # load best model weights\n",
    "        self.model.load_state_dict(self.best_model_wts)\n",
    "\n",
    "\n",
    "    def exexute_train(self):\n",
    "        self.train_model()\n",
    "\n",
    "        # metrics plot\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(self.train_loss_list, label='train loss',\n",
    "                 marker='o', color='k')\n",
    "        plt.plot(self.val_loss_list, label='val loss',\n",
    "                 marker='o', linestyle='--', color='k')\n",
    "\n",
    "        plt.plot(self.train_prec_list, label='train prec',\n",
    "                 marker='v', color='b')\n",
    "        plt.plot(self.val_prec_list, label='val prec',\n",
    "                 marker='v', linestyle='--', color='b')\n",
    "        \n",
    "        plt.plot(self.train_px_acc_list, label='train IOU',\n",
    "                 marker='v', color='g')\n",
    "        plt.plot(self.val_px_acc_list, label='val IOU',\n",
    "                 marker='v', linestyle='--', color='g')\n",
    "\n",
    "        plt.xticks(range(len(self.train_loss_list)))\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('value')\n",
    "        plt.legend()\n",
    "        plt.show\n",
    "\n",
    "\n",
    "    def execute_external_train(self):\n",
    "        self.model, self.metrics_list = train_model_externally(model=self.model,\n",
    "                                                                dat_load=self.dataloaders_dict,\n",
    "                                                                optimizer=self.optimizer,\n",
    "                                                                scheduler=self.scheduler,\n",
    "                                                                num_epochs=self.n_epoch)\n",
    "        \n",
    "        # metrics plot\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(self.metrics_list[0], label='train loss',\n",
    "                 marker='o', color='k')\n",
    "        plt.plot(self.metrics_list[1], label='val loss',\n",
    "                 marker='o', linestyle='--', color='k')\n",
    "\n",
    "        plt.plot(self.metrics_list[4], label='train prec',\n",
    "                 marker='v', color='b')\n",
    "        plt.plot(self.metrics_list[5], label='val prec',\n",
    "                 marker='v', linestyle='--', color='b')\n",
    "        \n",
    "        plt.plot(self.metrics_list[2], label='train IOU',\n",
    "                 marker='v', color='g')\n",
    "        plt.plot(self.metrics_list[3], label='val IOU',\n",
    "                 marker='v', linestyle='--', color='g')\n",
    "\n",
    "        plt.xticks(range(len(self.train_loss_list)))\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('value')\n",
    "        plt.legend()\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_datadict = get_dataloaders(combined_data=combined, segmented_data=segmented,\n",
    "#                                     train_samp_size=1000, val_samp_size=500, batch_size=5)\n",
    "\n",
    "training_datadict = get_synth_dataloaders(train_samp_size=1000, val_samp_size=500, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TrainRun(unet_model=UNet, dataloaders_dict=training_datadict,\n",
    "                    n_epoch=3, n_class=2, loss_type='iou', loss_bce_weight=0.75, init_lr=0.001)\n",
    "training.execute_external_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "test_dataset = M2NISTData(combined=combined, segmented=segmented,\n",
    "                          samp_size=5000, samp_type='trn', transform=demo_trans)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "test_inputs, test_labels = next(iter(test_dataloader))\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = shapes_demo_trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0], std=[1])])\n",
    "\n",
    "test_dataloader = DataLoader(dataset=ShapesData(samp_size=100, transform=trans), batch_size=5, shuffle=True)\n",
    "test_inputs, test_labels = next(iter(test_dataloader))\n",
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_inputs = test_inputs.to(device)\n",
    "\n",
    "model.eval()\n",
    "test_pred = model(test_inputs)\n",
    "\n",
    "test_pred = F.relu6(test_pred)\n",
    "# test_pred = torch.softmax(test_pred, dim=1)\n",
    "test_pred = test_pred.data.cpu().numpy()\n",
    "print(test_pred.shape)\n",
    "\n",
    "\n",
    "i = 2\n",
    "one_lab, two_lab = 6, 8\n",
    " \n",
    "fig, ax = plt.subplots(ncols=2,nrows=3, figsize=(10,15))\n",
    "ax[0,0].imshow(test_inputs[i,0], cmap='Greys_r')\n",
    "ax[0,1].imshow(test_pred[i,-1], cmap='jet')\n",
    "ax[1,0].imshow(test_labels[i,one_lab], cmap='jet')\n",
    "ax[2,0].imshow(test_labels[i,two_lab], cmap='jet')\n",
    "ax[1,1].imshow(test_pred[i,one_lab], cmap='jet', vmin=0)\n",
    "ax[2,1].imshow(test_pred[i,two_lab], cmap='jet', vmin=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
