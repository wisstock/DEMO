{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet demo\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/\n",
    "# https://towardsdatascience.com/cook-your-first-u-net-in-pytorch-b3297a844cf3\n",
    "# https://github.com/Mostafa-wael/U-Net-in-PyTorch/tree/main\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d, Dropout2d, MaxPool2d, ReLU, UpsamplingNearest2d\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision import ops\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image. \n",
    "        # Each block in the encoder consists of two convolutional layers followed by a max-pooling layer, with the exception of the last baseline block which does not include a max-pooling layer.\n",
    "        # -------\n",
    "        # input: 572x572x3\n",
    "        self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1) # output: 570x570x64\n",
    "        self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1) # output: 568x568x64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 284x284x64\n",
    "\n",
    "        # input: 284x284x64\n",
    "        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 282x282x128\n",
    "        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 280x280x128\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n",
    "\n",
    "        # input: 140x140x128\n",
    "        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 138x138x256\n",
    "        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 136x136x256\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n",
    "\n",
    "        # input: 68x68x256\n",
    "        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 66x66x512\n",
    "        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 64x64x512\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n",
    "\n",
    "\n",
    "        # Baseline\n",
    "        # input: 32x32x512\n",
    "        self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) # output: 30x30x1024\n",
    "        self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1) # output: 28x28x1024\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "        \n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetMini(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNetMini, self).__init__()\n",
    "\n",
    "        # Use padding 1 to mimic `padding='same'` in keras,\n",
    "        # use this visualization tool https://ezyang.github.io/convolution-visualizer/index.html\n",
    "        self.block1 = Sequential(\n",
    "            Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.pool1 = MaxPool2d((2, 2))\n",
    "\n",
    "        self.block2 = Sequential(\n",
    "            Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "        )\n",
    "        self.pool2 = MaxPool2d((2, 2))\n",
    "\n",
    "        self.block3 = Sequential(\n",
    "            Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = UpsamplingNearest2d(scale_factor=2)\n",
    "        self.block4 = Sequential(\n",
    "            Conv2d(192, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        self.up2 = UpsamplingNearest2d(scale_factor=2)\n",
    "        self.block5 = Sequential(\n",
    "            Conv2d(96, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Dropout2d(0.2),\n",
    "            Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2d = Conv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.block1(x)\n",
    "        out_pool1 = self.pool1(out1)\n",
    "\n",
    "        out2 = self.block2(out_pool1)\n",
    "        out_pool2 = self.pool1(out2)\n",
    "\n",
    "        out3 = self.block3(out_pool2)\n",
    "\n",
    "        out_up1 = self.up1(out3)\n",
    "        # return out_up1\n",
    "        out4 = torch.cat((out_up1, out2), dim=1)\n",
    "        out4 = self.block4(out4)\n",
    "\n",
    "        out_up2 = self.up2(out4)\n",
    "        out5 = torch.cat((out_up2, out1), dim=1)\n",
    "        out5 = self.block5(out5)\n",
    "\n",
    "        out = self.conv2d(out5)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(height, width, count):\n",
    "    x, y = zip(*[generate_img_and_mask(height, width) for i in range(0, count)])\n",
    "\n",
    "    X = np.asarray(x) * 255\n",
    "    X = X.repeat(3, axis=1).transpose([0, 2, 3, 1]).astype(np.uint8)\n",
    "    Y = np.asarray(y)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def generate_img_and_mask(height, width):\n",
    "    shape = (height, width)\n",
    "\n",
    "    # triangle_location = get_random_location(*shape)\n",
    "    circle_location1 = get_random_location(*shape, zoom=0.7)\n",
    "    circle_location2 = get_random_location(*shape, zoom=0.5)\n",
    "    # mesh_location = get_random_location(*shape)\n",
    "    # square_location = get_random_location(*shape, zoom=0.8)\n",
    "    # plus_location = get_random_location(*shape, zoom=1.2)\n",
    "\n",
    "    # Create input image\n",
    "    arr = np.zeros(shape, dtype=bool)\n",
    "    # arr = add_triangle(arr, *triangle_location)\n",
    "    arr = add_circle(arr, *circle_location1)\n",
    "    arr = add_circle(arr, *circle_location2, fill=True)\n",
    "    # arr = add_mesh_square(arr, *mesh_location)\n",
    "    # arr = add_filled_square(arr, *square_location)\n",
    "    # arr = add_plus(arr, *plus_location)\n",
    "    arr = np.reshape(arr, (1, height, width)).astype(np.float32)\n",
    "\n",
    "    # Create target masks\n",
    "    masks = np.asarray([\n",
    "        # add_filled_square(np.zeros(shape, dtype=bool), *square_location),\n",
    "        add_circle(np.zeros(shape, dtype=bool), *circle_location2, fill=True),\n",
    "        # add_triangle(np.zeros(shape, dtype=bool), *triangle_location),\n",
    "        add_circle(np.zeros(shape, dtype=bool), *circle_location1),\n",
    "        #  add_filled_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
    "        # add_mesh_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
    "        # add_plus(np.zeros(shape, dtype=bool), *plus_location)\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    return arr, masks\n",
    "\n",
    "\n",
    "def add_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "    arr[x-s,y-s:y+s] = True\n",
    "    arr[x+s,y-s:y+s] = True\n",
    "    arr[x-s:x+s,y-s] = True\n",
    "    arr[x-s:x+s,y+s] = True\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def add_filled_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "\n",
    "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, yy > y - s, yy < y + s]))\n",
    "\n",
    "\n",
    "def logical_and(arrays):\n",
    "    new_array = np.ones(arrays[0].shape, dtype=bool)\n",
    "    for a in arrays:\n",
    "        new_array = np.logical_and(new_array, a)\n",
    "\n",
    "    return new_array\n",
    "\n",
    "\n",
    "def add_mesh_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "\n",
    "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, xx % 2 == 1, yy > y - s, yy < y + s, yy % 2 == 1]))\n",
    "\n",
    "\n",
    "def add_triangle(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    triangle = np.tril(np.ones((size, size), dtype=bool))\n",
    "\n",
    "    arr[x-s:x-s+triangle.shape[0],y-s:y-s+triangle.shape[1]] = triangle\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def add_circle(arr, x, y, size, fill=False):\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "    circle = np.sqrt((xx - x) ** 2 + (yy - y) ** 2)\n",
    "    new_arr = np.logical_or(arr, np.logical_and(circle < size, circle >= size * 0.7 if not fill else True))\n",
    "\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def add_plus(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "    arr[x-1:x+1,y-s:y+s] = True\n",
    "    arr[x-s:x+s,y-1:y+1] = True\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_random_location(width, height, zoom=1.0):\n",
    "    x = int(width * random.uniform(0.1, 0.9))\n",
    "    y = int(height * random.uniform(0.1, 0.9))\n",
    "\n",
    "    size = int(min(width, height) * random.uniform(0.06, 0.12) * zoom)\n",
    "\n",
    "    return (x, y, size)\n",
    "\n",
    "\n",
    "def plot_img_array(img_array, ncol=3):\n",
    "    nrow = len(img_array) // ncol\n",
    "\n",
    "    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4))\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        plots[i // ncol, i % ncol]\n",
    "        plots[i // ncol, i % ncol].imshow(img_array[i])\n",
    "\n",
    "\n",
    "def plot_side_by_side(img_arrays):\n",
    "    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n",
    "\n",
    "    plot_img_array(np.array(flatten_list), ncol=len(img_arrays))\n",
    "\n",
    "\n",
    "def plot_errors(results_dict, title):\n",
    "    markers = itertools.cycle(('+', 'x', 'o'))\n",
    "\n",
    "    plt.title('{}'.format(title))\n",
    "\n",
    "    for label, result in sorted(results_dict.items()):\n",
    "        plt.plot(result, marker=next(markers), label=label)\n",
    "        plt.ylabel('dice_coef')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(loc=3, bbox_to_anchor=(1, 0))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def masks_to_colorimg(masks):\n",
    "    colors = np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n",
    "\n",
    "    colorimg = np.ones((masks.shape[1], masks.shape[2], 3), dtype=np.float32) * 255\n",
    "    channels, height, width = masks.shape\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            selected_colors = colors[masks[:,y,x] > 0.5]\n",
    "\n",
    "            if len(selected_colors) > 0:\n",
    "                colorimg[y,x,:] = np.mean(selected_colors, axis=0)\n",
    "\n",
    "    return colorimg.astype(np.uint8)\n",
    "\n",
    "\n",
    "def generate_images_and_masks_then_plot():\n",
    "    # Generate some random images\n",
    "    input_images, target_masks = generate_random_data(192, 192, count=3)\n",
    "\n",
    "    for x in [input_images, target_masks]:\n",
    "        print(x.shape)\n",
    "        print(x.min(), x.max())\n",
    "\n",
    "    # Change channel-order and make 3 channels for matplot\n",
    "    input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "    # Map each channel (i.e. class) to each color\n",
    "    target_masks_rgb = [masks_to_colorimg(x) for x in target_masks]\n",
    "\n",
    "    # Left: Input image (black and white), Right: Target mask (6ch)\n",
    "    plot_side_by_side([input_images_rgb, target_masks_rgb])\n",
    "\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self, count, transform=None):\n",
    "        self.input_images, self.target_masks = generate_random_data(192, 192, count=count)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders():\n",
    "    # use the same transformations for train/val in this example\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "    ])\n",
    "\n",
    "    train_set = SimDataset(500, transform = trans)\n",
    "    val_set = SimDataset(100, transform = trans)\n",
    "\n",
    "    image_datasets = {\n",
    "        'train': train_set, 'val': val_set\n",
    "    }\n",
    "\n",
    "    batch_size = 20\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "        'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    }\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [Segmentation Metrics PyTorch Implementation](https://github.com/hsiangyuzhao/Segmentation-Metrics-PyTorch)\n",
    "\n",
    "#### Pixel accuracy\n",
    "Pixel accuracy measures how many pixels are predicted correctly. In binary cases:  \n",
    "\n",
    "$\n",
    "Pixel Acc = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$  \n",
    "\n",
    "In multiclass cases it can be calculated from confusion matrix, by dividing the sum of diagonal elements (ture positives for all classes) with the total number of pixels.\n",
    "\n",
    "#### Dice coeff\n",
    "Dice evaluates the overlap rate of prediction results and ground truth; equals to f1 score in defination.  \n",
    "\n",
    "$\n",
    "Dice = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}\n",
    "$  \n",
    "\n",
    "#### Precision\n",
    "Describes the purity of our positive detections relative to the ground truth.  \n",
    "\n",
    "$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$  \n",
    "\n",
    "#### Recall\n",
    "Describes the completeness of our positive predictions relative to the ground truth.  \n",
    "\n",
    "$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$  \n",
    "\n",
    "### Specificity\n",
    "Also known as true negative rate (TNR)  \n",
    "\n",
    "$\n",
    "Specificity = \\frac{TN}{TN + FP}\n",
    "$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice_loss(pred, target, smooth=1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "def overlap_metrics(pred, target, eps=1e-5):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    tp = torch.sum(pred * target)  # TP\n",
    "    fp = torch.sum(pred * (1 - target))  # FP\n",
    "    fn = torch.sum((1 - pred) * target)  # FN\n",
    "    tn = torch.sum((1 - pred) * (1 - target))  # TN\n",
    "\n",
    "    pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
    "    dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
    "    iou = (tp + eps) / (tp + fp + fn + eps)\n",
    "    precision = (tp + eps) / (tp + fp + eps)\n",
    "    recall = (tp + eps) / (tp + fn + eps)\n",
    "    specificity = (tn + eps) / (tn + fp + eps)       \n",
    "\n",
    "    return [pixel_acc, dice, precision, recall, specificity]\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    o_m = overlap_metrics(pred, target)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "    metrics['px_acc'] += o_m[0].data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice_coef'] += o_m[1].data.cpu().numpy() * target.size(0)\n",
    "    metrics['prec'] += o_m[2].data.cpu().numpy() * target.size(0)\n",
    "    metrics['recall'] += o_m[3].data.cpu().numpy() * target.size(0)\n",
    "    metrics['spec'] += o_m[4].data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "\n",
    "\n",
    "def train_model(model, dat_load, optimizer, scheduler, num_epochs=50):\n",
    "    dataloaders = dat_load\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    train_px_acc_list = []\n",
    "    val_px_acc_list = []\n",
    "\n",
    "    train_prec_list = []\n",
    "    val_prec_list = []\n",
    "\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('=' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    print(loss)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "            \n",
    "            if phase == 'train':\n",
    "                print(metrics['loss'])\n",
    "                train_loss_list.append(metrics['loss'] / epoch_samples)\n",
    "                train_px_acc_list.append(metrics['px_acc'] / epoch_samples)\n",
    "                train_prec_list.append(metrics['prec'] / epoch_samples)\n",
    "            else:\n",
    "                val_loss_list.append(metrics['loss'] / epoch_samples)\n",
    "                val_px_acc_list.append(metrics['px_acc'] / epoch_samples)\n",
    "                val_prec_list.append(metrics['prec'] / epoch_samples)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    " \n",
    "    total_time_elapsed = time.time() - train_start_time \n",
    "    print('Best val loss: {:4f}, total train time {:.0f}m {:.0f}s'.format(best_loss, total_time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, [train_loss_list, val_loss_list, train_px_acc_list, val_px_acc_list, train_prec_list, val_prec_list]\n",
    "\n",
    "\n",
    "def run(UNet):\n",
    "    num_class = 3\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = UNet(num_class).to(device)\n",
    "\n",
    "    optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "    model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=50)\n",
    "\n",
    "    model.eval()  # Set model to the evaluation mode\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # imagenet\n",
    "    ])\n",
    "    # # Create another simulation dataset for test\n",
    "    test_dataset = SimDataset(3, transform = trans)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Get the first batch\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Predict\n",
    "    pred = model(inputs)\n",
    "    # The loss functions include the sigmoid function.\n",
    "    pred = F.sigmoid(pred)\n",
    "    pred = pred.data.cpu().numpy()\n",
    "    print(pred.shape)\n",
    "\n",
    "    # Change channel-order and make 3 channels for matplot\n",
    "    input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "    # Map each channel (i.e. class) to each color\n",
    "    target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "    pred_rgb = [masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "    plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainRun():\n",
    "    def __init__(self, unet_model,\n",
    "                 n_epoch=5, n_class=3, n_test=2,\n",
    "                 train_set_size=100, val_set_size=20):\n",
    "        self.n_class = n_class\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_test = n_test\n",
    "\n",
    "        self.train_set_size = train_set_size\n",
    "        self.val_set_size = val_set_size\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = unet_model(self.n_class).to(self.device)\n",
    "\n",
    "        self.optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=1e-4)\n",
    "        self.exp_lr_scheduler = lr_scheduler.StepLR(self.optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_data_loaders__(train_set_size=500, val_set_size=100):\n",
    "        # use the same transformations for train/val in this example\n",
    "        trans = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "        train_set = SimDataset(train_set_size, transform = trans)\n",
    "        val_set = SimDataset(val_set_size, transform = trans)\n",
    "\n",
    "        image_datasets = {'train': train_set,\n",
    "                          'val': val_set}\n",
    "        \n",
    "        batch_size = 10\n",
    "        dataloaders = {'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1),\n",
    "                       'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)}\n",
    "\n",
    "        return image_datasets, dataloaders\n",
    "\n",
    "    def exexute_train(self):\n",
    "        self.image_dataset, self.dataloader = self.__get_data_loaders__(self.train_set_size, self.val_set_size)\n",
    "\n",
    "        self.model, self.metrics_list = train_model(self.model, self.dataloader,\n",
    "                                                    self.optimizer_ft, self.exp_lr_scheduler,\n",
    "                                                    num_epochs=self.n_epoch)\n",
    "\n",
    "        self.train_loss = self.metrics_list[0]\n",
    "        self.val_loss = self.metrics_list[1]\n",
    "        self.train_px_acc = self.metrics_list[2]\n",
    "        self.val_px_acc = self.metrics_list[3]\n",
    "        self.train_prec = self.metrics_list[4]\n",
    "        self.val_prec = self.metrics_list[5]\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(self.train_loss, label='train loss',\n",
    "                 marker='o', color='k')\n",
    "        plt.plot(self.val_loss, label='validation loss',\n",
    "                 marker='o', linestyle='--', color='k')\n",
    "        \n",
    "        plt.plot(self.train_px_acc, label='train px accuracy',\n",
    "                 marker='^', color='r')\n",
    "        plt.plot(self.val_px_acc, label='validation px accuracy',\n",
    "                 marker='^', linestyle='--', color='r')\n",
    "\n",
    "        plt.plot(self.train_prec, label='train precision',\n",
    "                 marker='v', color='b')\n",
    "        plt.plot(self.val_prec, label='validation precision',\n",
    "                 marker='v', linestyle='--', color='b')\n",
    "\n",
    "        plt.xticks(range(len(self.train_loss)))\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('value')\n",
    "        plt.legend()\n",
    "        plt.show\n",
    "\n",
    "    def execute_test(self, test_set_size=2):\n",
    "        self.model.eval()  # Set model to the evaluation mode\n",
    "\n",
    "        trans = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "        \n",
    "        # # Create another simulation dataset for test\n",
    "        self.test_dataset = SimDataset(test_set_size, transform = trans)\n",
    "        test_loader = DataLoader(self.test_dataset, batch_size=test_set_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Get the first batch\n",
    "        inputs, labels = next(iter(test_loader))\n",
    "        self.inputs = inputs.to(device)\n",
    "        self.labels = labels.to(device)\n",
    "\n",
    "        # Predict\n",
    "        self.pred = self.model(inputs)\n",
    "        # The loss functions include the sigmoid function.\n",
    "        self.pred = F.sigmoid(self.pred)\n",
    "        self.pred = self.pred.data.cpu().numpy()\n",
    "        print(self.pred.shape)\n",
    "\n",
    "        for i in range(inputs.cpu().numpy().shape[0]):\n",
    "            one_img = self.inputs.cpu()[i]\n",
    "            one_img = torch.swapdims(self.inputs.cpu()[0], 0, -1).to(torch.uint8)\n",
    "            one_msk = self.labels.cpu()[i]\n",
    "            one_msk = torch.swapdims(torch.cat((one_msk, torch.unsqueeze(torch.zeros_like(one_msk[0]), 0)), dim=0),0,-1)\n",
    "            one_prd = torch.tensor(self.pred[i])\n",
    "            one_prd = torch.swapdims(torch.cat((one_prd, torch.unsqueeze(torch.zeros_like(one_prd[0]), 0)), dim=0),0,-1)\n",
    "\n",
    "            fig, ax = plt.subplots(ncols=3, figsize=(15,5))\n",
    "            ax[0].imshow(one_img)\n",
    "            ax[0].set_title('Img')\n",
    "            ax[0].set_axis_off()\n",
    "            ax[1].imshow(one_msk)\n",
    "            ax[1].set_title('Mask')\n",
    "            ax[1].set_axis_off()\n",
    "            ax[2].imshow(one_prd)\n",
    "            ax[2].set_title('Segmentation')\n",
    "            ax[2].set_axis_off()\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train = TrainRun(UNet, n_epoch=1, n_class=2)\n",
    "demo_train.exexute_train()\n",
    "demo_train.execute_test(test_set_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_msk = torch.tensor(demo_train.pred[0])\n",
    "one_msk = torch.swapdims(torch.cat((one_msk, torch.unsqueeze(torch.zeros_like(one_msk[0]), 0)), dim=0),0,-1)\n",
    "# a = torch.swapdims(demo_train.inputs.cpu()[0], 0, -1).to(torch.uint8)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(one_msk[...,1], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(demo_train.model.state_dict(), '308_cirt-ring_unet.pt')\n",
    "\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
